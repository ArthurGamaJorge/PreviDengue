{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKtlOj4__2QQ"
      },
      "source": [
        "# Iniciando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc22D1nfxMRp",
        "outputId": "a84a852d-c238-4a3b-b33b-a9d81d73157a"
      },
      "outputs": [],
      "source": [
        "!pip install sympy\n",
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5YCXAyVx9kQ",
        "outputId": "9791adb3-d830-4fc2-f7f4-08965813de12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L8AJdbC2yWd"
      },
      "source": [
        "# Criar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qscojQLPADG1",
        "outputId": "44df4638-35d6-452a-fb33-cd615784c36f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_seed: 42\n",
            "original total images: 251\n",
            "train source images: 197\n",
            "test source images: 54\n",
            "train tiles: 1682\n",
            "test tiles: 810\n",
            "train boxes: 6798\n",
            "test boxes: 1643\n",
            "train class distribution: {0: 112, 1: 103, 2: 745, 3: 1713, 4: 391, 5: 1742, 6: 1992}\n",
            "test class distribution: {0: 14, 1: 20, 2: 208, 3: 490, 4: 117, 5: 227, 6: 567}\n",
            "dataset.yml: /content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml\n",
            "nc: 7\n",
            "names: ['piscina_limpa', 'piscina_suja', 'lona', 'monte_de_lixo', 'reservatorio_de_agua', 'pneu', 'saco_de_lixo']\n"
          ]
        }
      ],
      "source": [
        "# TILES\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import yaml\n",
        "from PIL import Image\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Sao_Carlos_imagens\"\n",
        "labels_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Sao_Carlos_finalAnnotations\"\n",
        "output_root = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2\"\n",
        "tiles_root = os.path.join(output_root, \"tiles\")\n",
        "train_root = os.path.join(tiles_root, \"train\")\n",
        "test_root = os.path.join(tiles_root, \"test\")\n",
        "os.makedirs(train_root, exist_ok=True)\n",
        "os.makedirs(test_root, exist_ok=True)\n",
        "\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "\n",
        "tile_size = 1024\n",
        "overlap = 0.2\n",
        "keep_negative_tiles = True\n",
        "\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "def numeric_key(filename):\n",
        "    name = Path(filename).stem\n",
        "    m = re.match(r\"^(\\d+)$\", name)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    nums = re.findall(r\"\\d+\", name)\n",
        "    return int(nums[0]) if nums else name\n",
        "\n",
        "def list_images(dirpath):\n",
        "    return [f for f in os.listdir(dirpath) if Path(f).suffix.lower() in image_extensions]\n",
        "\n",
        "all_images = sorted(list_images(images_dir), key=numeric_key)\n",
        "if not all_images:\n",
        "    raise SystemExit(\"no images found in images_dir\")\n",
        "\n",
        "def ensure_label_file(labels_dir, stem):\n",
        "    src = os.path.join(labels_dir, stem + \".txt\")\n",
        "    if not os.path.exists(src):\n",
        "        open(src, \"a\").close()\n",
        "    return src\n",
        "\n",
        "def read_yolo_labels(path):\n",
        "    boxes = []\n",
        "    try:\n",
        "        with open(path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if not parts:\n",
        "                    continue\n",
        "                cls = int(float(parts[0]))\n",
        "\n",
        "                # Classes a serem removidas: 'lixo' (5) e 'Monte_de_objetos' (8)\n",
        "                if cls in [5, 8]:\n",
        "                    continue\n",
        "\n",
        "                if cls > 5:\n",
        "                    cls -= 1\n",
        "\n",
        "                x_center = float(parts[1])\n",
        "                y_center = float(parts[2])\n",
        "                w = float(parts[3])\n",
        "                h = float(parts[4])\n",
        "                boxes.append((cls, x_center, y_center, w, h))\n",
        "    except:\n",
        "        pass\n",
        "    return boxes\n",
        "\n",
        "def yolo_to_abs(box, img_w, img_h):\n",
        "    cls, x_c, y_c, w, h = box\n",
        "    x_c *= img_w\n",
        "    y_c *= img_h\n",
        "    w *= img_w\n",
        "    h *= img_h\n",
        "    x1 = x_c - w / 2\n",
        "    y1 = y_c - h / 2\n",
        "    x2 = x_c + w / 2\n",
        "    y2 = y_c + h / 2\n",
        "    return cls, x1, y1, x2, y2\n",
        "\n",
        "def abs_to_yolo(cls, x1, y1, x2, y2, tile_w, tile_h):\n",
        "    w = max(1e-6, x2 - x1)\n",
        "    h = max(1e-6, y2 - y1)\n",
        "    x_c = (x1 + x2) / 2 / tile_w\n",
        "    y_c = (y1 + y2) / 2 / tile_h\n",
        "    return f\"{cls} {x_c:.6f} {y_c:.6f} {w/tile_w:.6f} {h/tile_h:.6f}\"\n",
        "\n",
        "def dominant_class_for_image(boxes):\n",
        "    if not boxes:\n",
        "        return -1\n",
        "    counter = Counter([b[0] for b in boxes])\n",
        "    return counter.most_common(1)[0][0]\n",
        "\n",
        "# Coleta metadados das imagens\n",
        "image_meta = []\n",
        "for img_name in all_images:\n",
        "    stem = Path(img_name).stem\n",
        "    lbl = ensure_label_file(labels_dir, stem)\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            w, h = im.size\n",
        "    except:\n",
        "        continue\n",
        "    boxes = read_yolo_labels(lbl)\n",
        "    dom = dominant_class_for_image(boxes)\n",
        "    image_meta.append({\"img\": img_name, \"stem\": stem, \"w\": w, \"h\": h, \"boxes\": boxes, \"dom\": dom})\n",
        "\n",
        "# Estratificação por classe dominante\n",
        "groups = defaultdict(list)\n",
        "for m in image_meta:\n",
        "    groups[m[\"dom\"]].append(m)\n",
        "\n",
        "train_images = []\n",
        "test_images = []\n",
        "for dom, items in groups.items():\n",
        "    random.shuffle(items)\n",
        "    split = int(0.8 * len(items))\n",
        "    train_images.extend(items[:split])\n",
        "    test_images.extend(items[split:])\n",
        "\n",
        "# Função para criar tiles\n",
        "def make_tiles_for_image(meta, out_dir, tile_size=1024, overlap=0.2, keep_neg=False):\n",
        "    img_name = meta[\"img\"]\n",
        "    stem = meta[\"stem\"]\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    abs_boxes = [yolo_to_abs(b, meta[\"w\"], meta[\"h\"]) for b in meta[\"boxes\"]]\n",
        "    stride = int(tile_size * (1 - overlap))\n",
        "    with Image.open(img_path) as im:\n",
        "        W, H = im.size\n",
        "        x_starts = list(range(0, max(1, W - tile_size + 1), stride))\n",
        "        y_starts = list(range(0, max(1, H - tile_size + 1), stride))\n",
        "        if x_starts and x_starts[-1] + tile_size < W:\n",
        "            x_starts.append(W - tile_size)\n",
        "        if y_starts and y_starts[-1] + tile_size < H:\n",
        "            y_starts.append(H - tile_size)\n",
        "        for xi, x in enumerate(x_starts):\n",
        "            for yi, y in enumerate(y_starts):\n",
        "                box_list = []\n",
        "                tile_x1, tile_y1 = x, y\n",
        "                tile_x2, tile_y2 = x + tile_size, y + tile_size\n",
        "                for cls, x1, y1, x2, y2 in abs_boxes:\n",
        "                    cx = (x1 + x2) / 2\n",
        "                    cy = (y1 + y2) / 2\n",
        "                    if (cx >= tile_x1) and (cx <= tile_x2) and (cy >= tile_y1) and (cy <= tile_y2):\n",
        "                        nx1 = max(tile_x1, x1) - tile_x1\n",
        "                        ny1 = max(tile_y1, y1) - tile_y1\n",
        "                        nx2 = min(tile_x2, x2) - tile_x1\n",
        "                        ny2 = min(tile_y2, y2) - tile_y1\n",
        "                        box_list.append((cls, nx1, ny1, nx2, ny2))\n",
        "                if not box_list and not keep_neg:\n",
        "                    continue\n",
        "                tile = im.crop((tile_x1, tile_y1, tile_x2, tile_y2))\n",
        "                tile_name = f\"{stem}_tx{xi}_ty{yi}.jpg\"\n",
        "                tile_img_dir = os.path.join(out_dir, \"images\")\n",
        "                tile_lbl_dir = os.path.join(out_dir, \"labels\")\n",
        "                os.makedirs(tile_img_dir, exist_ok=True)\n",
        "                os.makedirs(tile_lbl_dir, exist_ok=True)\n",
        "                tile.save(os.path.join(tile_img_dir, tile_name), quality=95)\n",
        "                lbl_lines = [abs_to_yolo(cls, nx1, ny1, nx2, ny2, tile_size, tile_size) for cls, nx1, ny1, nx2, ny2 in box_list]\n",
        "                with open(os.path.join(tile_lbl_dir, tile_name.replace(\".jpg\", \".txt\")), \"w\") as lf:\n",
        "                    lf.write(\"\\n\".join(lbl_lines))\n",
        "\n",
        "# Criar tiles para treino e teste\n",
        "for img_meta in train_images:\n",
        "    make_tiles_for_image(img_meta, train_root, tile_size=tile_size, overlap=overlap, keep_neg=keep_negative_tiles)\n",
        "for img_meta in test_images:\n",
        "    make_tiles_for_image(img_meta, test_root, tile_size=tile_size, overlap=overlap, keep_neg=True)\n",
        "\n",
        "# Contar boxes por classe\n",
        "def count_boxes_in_folder(labels_folder):\n",
        "    counter = Counter()\n",
        "    total = 0\n",
        "    labels_path = os.path.join(labels_folder, \"labels\")\n",
        "    if not os.path.isdir(labels_path):\n",
        "        return total, dict(sorted(counter.items()))\n",
        "    for f in os.listdir(labels_path):\n",
        "        if not f.endswith(\".txt\"):\n",
        "            continue\n",
        "        path = os.path.join(labels_path, f)\n",
        "        with open(path, \"r\") as fh:\n",
        "            for line in fh:\n",
        "                parts = line.strip().split()\n",
        "                if not parts:\n",
        "                    continue\n",
        "                try:\n",
        "                    cid = int(float(parts[0]))\n",
        "                    counter[cid] += 1\n",
        "                    total += 1\n",
        "                except:\n",
        "                    continue\n",
        "    return total, dict(sorted(counter.items()))\n",
        "\n",
        "train_img_count = len(os.listdir(os.path.join(train_root, \"images\"))) if os.path.isdir(os.path.join(train_root, \"images\")) else 0\n",
        "test_img_count = len(os.listdir(os.path.join(test_root, \"images\"))) if os.path.isdir(os.path.join(test_root, \"images\")) else 0\n",
        "train_total_boxes, train_dist = count_boxes_in_folder(train_root)\n",
        "test_total_boxes, test_dist = count_boxes_in_folder(test_root)\n",
        "\n",
        "names = [\n",
        "    'piscina_limpa',       # 0\n",
        "    'piscina_suja',        # 1\n",
        "    'lona',                # 2\n",
        "    'monte_de_lixo',       # 3\n",
        "    'reservatorio_de_agua',# 4\n",
        "    'pneu',                # 5 (era 6)\n",
        "    'saco_de_lixo'         # 6 (era 7)\n",
        "]\n",
        "nc = len(names)\n",
        "\n",
        "dataset_yml = {\n",
        "    \"train\": os.path.join(train_root, \"images\"),\n",
        "    \"test\": os.path.join(test_root, \"images\"),\n",
        "    \"val\": os.path.join(test_root, \"images\"),\n",
        "    \"nc\": nc,\n",
        "    \"names\": names\n",
        "}\n",
        "dataset_yml_path = os.path.join(output_root, \"dataset.yml\")\n",
        "with open(dataset_yml_path, \"w\") as yf:\n",
        "    yaml.dump(dataset_yml, yf, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "# Resumo\n",
        "print(\"random_seed:\", random_seed)\n",
        "print(\"original total images:\", len(all_images))\n",
        "print(\"train source images:\", len(train_images))\n",
        "print(\"test source images:\", len(test_images))\n",
        "print(\"train tiles:\", train_img_count)\n",
        "print(\"test tiles:\", test_img_count)\n",
        "print(\"train boxes:\", train_total_boxes)\n",
        "print(\"test boxes:\", test_total_boxes)\n",
        "print(\"train class distribution:\", train_dist)\n",
        "print(\"test class distribution:\", test_dist)\n",
        "print(\"dataset.yml:\", dataset_yml_path)\n",
        "print(\"nc:\", nc)\n",
        "print(\"names:\", names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alxsHrEA5SAL"
      },
      "source": [
        "# Criar dataset Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ih2bIuZG4lvh",
        "outputId": "90d24970-663b-4770-ef4a-f5d9179e4555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando processo de tiling para Hard Negative Mining (HNM)...\n",
            "Pasta de origem: /content/drive/MyDrive/tcc_dengue/ia_deteccao/fineTuning\n",
            "Pasta de destino LOCAL: /content/FineTuning_tiles_LOCAL\n",
            "\n",
            "Encontradas 64 imagens-fonte. Começando o tiling (local)...\n",
            "Processando 2.png... -> Criados 2 tiles.\n",
            "Processando 4.png... -> Criados 2 tiles.\n",
            "Processando 8.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 210203.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 210922.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 210956.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211022.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211053.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211200.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211213.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211256.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211349.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211453.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211541.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211704.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 211738.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212000.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212229.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212251.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212314.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212401.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212424.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212451.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212526.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212635.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212810.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212836.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 212946.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213045.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213146.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213350.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213429.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213518.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213609.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213658.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213724.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213751.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213900.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 213951.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 214110.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 214139.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 214855.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 214938.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215035.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215135.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215149.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215220.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215340.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215419.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215442.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215519.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215559.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215715.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215854.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 215958.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220025.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220036.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220132.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220152.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220355.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220411.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220433.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220446.png... -> Criados 2 tiles.\n",
            "Processando Captura de tela 2025-10-17 220521.png... -> Criados 2 tiles.\n",
            "\n",
            "--- Tiling Local Concluído ---\n",
            "Total de tiles de HNM criados localmente: 128\n",
            "Verificação local: 128 tiles existem na pasta local.\n",
            "\n",
            "Copiando 128 tiles para o Google Drive...\n",
            "De: /content/FineTuning_tiles_LOCAL/images\n",
            "Para: /content/drive/MyDrive/tcc_dengue/ia_deteccao/FineTuning_tiles/images\n",
            "Cópia para o Google Drive concluída!\n",
            "\n",
            "[PRÓXIMO PASSO]\n",
            "Copie todos os ficheiros de:\n",
            "'/content/drive/MyDrive/tcc_dengue/ia_deteccao/FineTuning_tiles/images'\n",
            "Para a sua pasta de treino original:\n",
            "'/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/images'\n"
          ]
        }
      ],
      "source": [
        "# Fine-Tuning\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "SOURCE_IMAGES_DIR = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/fineTuning\"\n",
        "LOCAL_TILES_ROOT = \"/content/FineTuning_tiles_LOCAL\"\n",
        "DRIVE_TILES_ROOT = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/FineTuning_tiles\"\n",
        "\n",
        "# Parâmetros de Tiling\n",
        "TILE_SIZE = 1024\n",
        "OVERLAP = 0.2\n",
        "IMAGE_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "# --- Funções Auxiliares (sem alteração) ---\n",
        "def numeric_key(filename):\n",
        "    \"\"\"Ordena os ficheiros de forma numérica.\"\"\"\n",
        "    name = Path(filename).stem\n",
        "    m = re.match(r\"^(\\d+)$\", name)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    nums = re.findall(r\"\\d+\", name)\n",
        "    return int(nums[0]) if nums else name\n",
        "\n",
        "def list_images(dirpath):\n",
        "    \"\"\"Lista todos os ficheiros de imagem num diretório.\"\"\"\n",
        "    return [f for f in os.listdir(dirpath) if Path(f).suffix.lower() in IMAGE_EXTENSIONS]\n",
        "\n",
        "# --- Função de Tiling (v3 - Nomes Sequenciais + RGBA fix) ---\n",
        "\n",
        "def make_hnm_tiles_for_image(img_path, out_dir, tile_size, overlap, counter_dict):\n",
        "    \"\"\"\n",
        "    Versão v3.\n",
        "    Usa um contador global para nomes sequenciais (ex: hnm_0001.jpg).\n",
        "    Também converte RGBA -> RGB.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            W, H = im.size\n",
        "\n",
        "            stride = int(tile_size * (1 - overlap))\n",
        "\n",
        "            x_starts = list(range(0, max(1, W - tile_size + 1), stride))\n",
        "            y_starts = list(range(0, max(1, H - tile_size + 1), stride))\n",
        "\n",
        "            if W > tile_size and (not x_starts or x_starts[-1] + tile_size < W):\n",
        "                 x_starts.append(W - tile_size)\n",
        "            if H > tile_size and (not y_starts or y_starts[-1] + tile_size < H):\n",
        "                 y_starts.append(H - tile_size)\n",
        "\n",
        "            if not x_starts:\n",
        "                x_starts = [0]\n",
        "            if not y_starts:\n",
        "                y_starts = [0]\n",
        "\n",
        "            tile_count = 0\n",
        "            for xi, x in enumerate(x_starts):\n",
        "                for yi, y in enumerate(y_starts):\n",
        "                    tile_x1, tile_y1 = x, y\n",
        "                    tile_x2, tile_y2 = x + tile_size, y + tile_size\n",
        "\n",
        "                    tile = im.crop((tile_x1, tile_y1, tile_x2, tile_y2))\n",
        "\n",
        "                    if tile.width == 0 or tile.height == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Lógica do Nome do Ficheiro Sequencial\n",
        "                    tile_name = f\"hnm_{counter_dict['value']:04d}.jpg\"\n",
        "                    counter_dict['value'] += 1\n",
        "\n",
        "                    tile_img_dir = os.path.join(out_dir, \"images\")\n",
        "                    os.makedirs(tile_img_dir, exist_ok=True)\n",
        "\n",
        "                    if tile.mode == 'RGBA':\n",
        "                        tile = tile.convert('RGB')\n",
        "\n",
        "                    tile.save(os.path.join(tile_img_dir, tile_name), quality=95)\n",
        "                    tile_count += 1\n",
        "\n",
        "            return tile_count\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  [ERRO] Falha ao processar {img_path}: {e}\")\n",
        "        return 0\n",
        "\n",
        "# --- Script Principal (Escrita Local + Cópia para o Drive) ---\n",
        "def main():\n",
        "    print(f\"Iniciando processo de tiling para Hard Negative Mining (HNM)...\")\n",
        "    print(f\"Pasta de origem: {SOURCE_IMAGES_DIR}\")\n",
        "    print(f\"Pasta de destino LOCAL: {LOCAL_TILES_ROOT}\")\n",
        "\n",
        "    # Limpa a pasta local, se já existir\n",
        "    if os.path.exists(LOCAL_TILES_ROOT):\n",
        "        print(f\"Limpando pasta local antiga: {LOCAL_TILES_ROOT}\")\n",
        "        shutil.rmtree(LOCAL_TILES_ROOT)\n",
        "\n",
        "    if not os.path.isdir(SOURCE_IMAGES_DIR):\n",
        "        print(f\"\\n[ERRO FATAL] A pasta de origem não existe: {SOURCE_IMAGES_DIR}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    all_images = sorted(list_images(SOURCE_IMAGES_DIR), key=numeric_key)\n",
        "\n",
        "    if not all_images:\n",
        "        print(f\"\\n[AVISO] Nenhuma imagem encontrada em {SOURCE_IMAGES_DIR}\")\n",
        "        return\n",
        "\n",
        "    # Inicializa o contador global\n",
        "    global_tile_counter = {\"value\": 1}\n",
        "\n",
        "    total_tiles_created = 0\n",
        "    print(f\"\\nEncontradas {len(all_images)} imagens-fonte. Começando o tiling (local)...\")\n",
        "\n",
        "    for img_name in all_images:\n",
        "        img_path = os.path.join(SOURCE_IMAGES_DIR, img_name)\n",
        "\n",
        "        # Salva na pasta LOCAL_TILES_ROOT\n",
        "        count = make_hnm_tiles_for_image(\n",
        "            img_path,\n",
        "            LOCAL_TILES_ROOT,\n",
        "            tile_size=TILE_SIZE,\n",
        "            overlap=OVERLAP,\n",
        "            counter_dict=global_tile_counter  # Passa o contador\n",
        "        )\n",
        "        if count > 0:\n",
        "            print(f\"Processando {img_name}... -> Criados {count} tiles.\")\n",
        "        total_tiles_created += count\n",
        "\n",
        "    print(\"\\n--- Tiling Local Concluído ---\")\n",
        "    print(f\"Total de tiles de HNM criados localmente: {total_tiles_created}\")\n",
        "\n",
        "    # Verifica a contagem local ANTES de copiar\n",
        "    local_img_folder = os.path.join(LOCAL_TILES_ROOT, \"images\")\n",
        "    if os.path.exists(local_img_folder):\n",
        "        real_count = len(os.listdir(local_img_folder))\n",
        "        print(f\"Verificação local: {real_count} tiles existem na pasta local.\")\n",
        "\n",
        "        if real_count == total_tiles_created and real_count > 0:\n",
        "            # Copia tudo de uma vez para o Google Drive\n",
        "            print(f\"\\nCopiando {real_count} tiles para o Google Drive...\")\n",
        "\n",
        "            drive_img_folder = os.path.join(DRIVE_TILES_ROOT, \"images\")\n",
        "\n",
        "            # Limpa a pasta de destino do Drive, se existir\n",
        "            if os.path.exists(drive_img_folder):\n",
        "                print(f\"Limpando pasta de destino antiga no Drive: {drive_img_folder}\")\n",
        "                shutil.rmtree(drive_img_folder)\n",
        "\n",
        "            print(f\"De: {local_img_folder}\")\n",
        "            print(f\"Para: {drive_img_folder}\")\n",
        "\n",
        "            shutil.copytree(local_img_folder, drive_img_folder)\n",
        "            print(\"Cópia para o Google Drive concluída!\")\n",
        "\n",
        "            print(\"\\n[PRÓXIMO PASSO]\")\n",
        "            print(\"Copie todos os ficheiros de:\")\n",
        "            print(f\"'{drive_img_folder}'\")\n",
        "            print(\"Para a sua pasta de treino original:\")\n",
        "            print(f\"'{os.path.join(output_root, 'tiles', 'train', 'images')}'\")\n",
        "        else:\n",
        "            print(f\"[ERRO] A contagem local ({real_count}) não bate com a esperada ({total_tiles_created}).\")\n",
        "    else:\n",
        "         print(\"[ERRO] A pasta local de tiles não foi criada.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    output_root = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2\"\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rhfXOPwu5phR",
        "outputId": "56ac41e3-5841-47b5-8e7f-b650f19137bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando recuperação de backgrounds descartados...\n",
            "Usando random_seed = 42 para replicar o split de treino.\n",
            "Coletando metadados das imagens-fonte...\n",
            "Replicando o split de treino estratificado 80/20...\n",
            "Split replicado. 197 imagens-fonte de treino encontradas.\n",
            "Começando o tiling (local) para salvar APENAS backgrounds...\n",
            "Processando 59.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 120.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 145.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 27.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 114.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 182.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 96.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 186.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 100.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 73.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 231.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 131.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 171.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 155.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 165.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 213.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 33.jpg... -> Salvos 13 tiles de background.\n",
            "Processando 153.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 66.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 146.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 174.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 1.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 215.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 98.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 204.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 248.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 173.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 237.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 160.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 101.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 118.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 74.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 250.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 167.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 226.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 82.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 200.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 247.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 20.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 151.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 175.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 249.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 2.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 86.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 87.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 183.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 161.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 3.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 88.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 39.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 91.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 235.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 246.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 191.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 17.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 54.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 108.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 11.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 65.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 9.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 242.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 181.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 40.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 36.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 5.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 7.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 176.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 23.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 142.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 55.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 76.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 245.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 79.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 141.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 89.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 67.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 106.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 51.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 198.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 126.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 95.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 240.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 154.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 30.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 122.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 148.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 15.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 60.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 57.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 52.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 230.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 168.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 211.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 208.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 75.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 68.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 10.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 205.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 170.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 83.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 32.jpg... -> Salvos 13 tiles de background.\n",
            "Processando 192.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 90.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 18.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 137.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 201.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 216.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 115.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 164.jpg... -> Salvos 13 tiles de background.\n",
            "Processando 193.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 184.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 26.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 53.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 25.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 29.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 78.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 244.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 105.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 156.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 214.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 158.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 111.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 163.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 143.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 139.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 34.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 119.jpg... -> Salvos 13 tiles de background.\n",
            "Processando 239.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 177.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 116.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 4.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 206.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 152.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 109.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 77.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 218.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 85.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 225.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 197.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 157.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 8.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 134.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 70.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 127.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 113.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 207.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 99.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 102.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 221.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 140.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 243.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 50.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 144.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 49.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 236.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 16.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 28.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 209.jpg... -> Salvos 6 tiles de background.\n",
            "Processando 123.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 232.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 64.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 93.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 227.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 190.jpg... -> Salvos 11 tiles de background.\n",
            "Processando 107.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 138.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 229.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 203.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 128.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 135.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 178.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 69.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 38.jpg... -> Salvos 4 tiles de background.\n",
            "Processando 71.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 43.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 47.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 41.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 44.jpg... -> Salvos 5 tiles de background.\n",
            "Processando 196.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 195.jpg... -> Salvos 3 tiles de background.\n",
            "Processando 46.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 187.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 185.jpg... -> Salvos 7 tiles de background.\n",
            "Processando 42.jpg... -> Salvos 1 tiles de background.\n",
            "Processando 61.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 94.jpg... -> Salvos 2 tiles de background.\n",
            "Processando 22.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 117.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 133.jpg... -> Salvos 10 tiles de background.\n",
            "Processando 179.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 159.jpg... -> Salvos 12 tiles de background.\n",
            "Processando 212.jpg... -> Salvos 14 tiles de background.\n",
            "Processando 241.jpg... -> Salvos 8 tiles de background.\n",
            "Processando 162.jpg... -> Salvos 9 tiles de background.\n",
            "Processando 125.jpg... -> Salvos 6 tiles de background.\n",
            "\n",
            "--- Tiling Local Concluído ---\n",
            "Total de tiles de background recuperados: 1273\n",
            "Verificação local: 1273 tiles existem na pasta local.\n",
            "\n",
            "Copiando 1273 tiles para o Google Drive...\n",
            "De: /content/Discarded_Backgrounds_LOCAL/images\n",
            "Para: /content/drive/MyDrive/tcc_dengue/ia_deteccao/Discarded_Backgrounds/images\n",
            "Cópia para o Google Drive concluída!\n",
            "\n",
            "[PRÓXIMO PASSO]\n",
            "Adicione os 1273 ficheiros de:\n",
            "'/content/drive/MyDrive/tcc_dengue/ia_deteccao/Discarded_Backgrounds/images'\n",
            "Para a sua pasta de treino original:\n",
            "'/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/images'\n"
          ]
        }
      ],
      "source": [
        "# Recuperar Backgrounds de treino\n",
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "# --- 1. CONFIGURAÇÃO ---\n",
        "images_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Sao_Carlos_imagens\"\n",
        "labels_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Sao_Carlos_finalAnnotations\"\n",
        "\n",
        "# Destino LOCAL (para velocidade e segurança)\n",
        "LOCAL_OUTPUT_ROOT = \"/content/Discarded_Backgrounds_LOCAL\"\n",
        "\n",
        "# Destino FINAL no seu Drive\n",
        "DRIVE_OUTPUT_ROOT = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Discarded_Backgrounds\"\n",
        "\n",
        "tile_size = 1024\n",
        "overlap = 0.2\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "def numeric_key(filename):\n",
        "    name = Path(filename).stem\n",
        "    m = re.match(r\"^(\\d+)$\", name)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    nums = re.findall(r\"\\d+\", name)\n",
        "    return int(nums[0]) if nums else name\n",
        "\n",
        "def list_images(dirpath):\n",
        "    return [f for f in os.listdir(dirpath) if Path(f).suffix.lower() in image_extensions]\n",
        "\n",
        "def ensure_label_file(labels_dir, stem):\n",
        "    src = os.path.join(labels_dir, stem + \".txt\")\n",
        "    if not os.path.exists(src):\n",
        "        open(src, \"a\").close()\n",
        "    return src\n",
        "\n",
        "def read_yolo_labels(path):\n",
        "    boxes = []\n",
        "    try:\n",
        "        with open(path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if not parts: continue\n",
        "                cls = int(float(parts[0]))\n",
        "                if cls in [5, 8]: continue\n",
        "                if cls > 5: cls -= 1\n",
        "                boxes.append((cls, float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])))\n",
        "    except:\n",
        "        pass\n",
        "    return boxes\n",
        "\n",
        "def yolo_to_abs(box, img_w, img_h):\n",
        "    cls, x_c, y_c, w, h = box\n",
        "    x_c *= img_w; y_c *= img_h; w *= img_w; h *= img_h\n",
        "    x1 = x_c - w / 2; y1 = y_c - h / 2\n",
        "    x2 = x_c + w / 2; y2 = y_c + h / 2\n",
        "    return cls, x1, y1, x2, y2\n",
        "\n",
        "def dominant_class_for_image(boxes):\n",
        "    if not boxes: return -1\n",
        "    counter = Counter([b[0] for b in boxes])\n",
        "    return counter.most_common(1)[0][0]\n",
        "\n",
        "# --- 3. FUNÇÃO DE TILING MODIFICADA (A Lógica Invertida) ---\n",
        "\n",
        "def save_negative_tiles_only(meta, out_dir, tile_size, overlap, counter_dict):\n",
        "    \"\"\"\n",
        "    Função modificada para salvar APENAS tiles de background.\n",
        "    \"\"\"\n",
        "    img_name = meta[\"img\"]\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "    abs_boxes = [yolo_to_abs(b, meta[\"w\"], meta[\"h\"]) for b in meta[\"boxes\"]]\n",
        "    stride = int(tile_size * (1 - overlap))\n",
        "\n",
        "    tile_count = 0\n",
        "\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            W, H = im.size\n",
        "            x_starts = list(range(0, max(1, W - tile_size + 1), stride))\n",
        "            y_starts = list(range(0, max(1, H - tile_size + 1), stride))\n",
        "\n",
        "            if W > tile_size and (not x_starts or x_starts[-1] + tile_size < W):\n",
        "                 x_starts.append(W - tile_size)\n",
        "            if H > tile_size and (not y_starts or y_starts[-1] + tile_size < H):\n",
        "                 y_starts.append(H - tile_size)\n",
        "\n",
        "            if not x_starts: x_starts = [0]\n",
        "            if not y_starts: y_starts = [0]\n",
        "\n",
        "            for xi, x in enumerate(x_starts):\n",
        "                for yi, y in enumerate(y_starts):\n",
        "                    tile_x1, tile_y1 = x, y\n",
        "                    tile_x2, tile_y2 = x + tile_size, y + tile_size\n",
        "\n",
        "                    # Verifica se algum label está no tile\n",
        "                    box_list = []\n",
        "                    for cls, x1, y1, x2, y2 in abs_boxes:\n",
        "                        cx = (x1 + x2) / 2\n",
        "                        cy = (y1 + y2) / 2\n",
        "                        if (cx >= tile_x1) and (cx <= tile_x2) and (cy >= tile_y1) and (cy <= tile_y2):\n",
        "                            box_list.append(True) # Só precisamos saber se tem *algum*\n",
        "                            break # Otimização: achou um, pode parar\n",
        "\n",
        "                    # --- A LÓGICA INVERTIDA ---\n",
        "                    if not box_list:\n",
        "                        # Se a lista de caixas (box_list) está VAZIA, é um background. SALVE!\n",
        "                        tile = im.crop((tile_x1, tile_y1, tile_x2, tile_y2))\n",
        "\n",
        "                        if tile.width == 0 or tile.height == 0: continue\n",
        "\n",
        "                        # Nome sequencial\n",
        "                        tile_name = f\"bg_{counter_dict['value']:05d}.jpg\" # 5 dígitos para ~1600+\n",
        "                        counter_dict['value'] += 1\n",
        "\n",
        "                        tile_img_dir = os.path.join(out_dir, \"images\")\n",
        "                        os.makedirs(tile_img_dir, exist_ok=True)\n",
        "\n",
        "                        if tile.mode == 'RGBA':\n",
        "                            tile = tile.convert('RGB')\n",
        "\n",
        "                        tile.save(os.path.join(tile_img_dir, tile_name), quality=95)\n",
        "                        tile_count += 1\n",
        "                    else:\n",
        "                        # Se a lista NÃO está vazia, é um tile positivo. IGNORE.\n",
        "                        continue\n",
        "        return tile_count\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  [ERRO] Falha ao processar {img_name}: {e}\")\n",
        "        return 0\n",
        "\n",
        "# --- 4. SCRIPT PRINCIPAL (Modificado) ---\n",
        "def main():\n",
        "    print(f\"Iniciando recuperação de backgrounds descartados...\")\n",
        "    print(f\"Usando random_seed = {random_seed} para replicar o split de treino.\")\n",
        "\n",
        "    all_images = sorted(list_images(images_dir), key=numeric_key)\n",
        "    if not all_images:\n",
        "        raise SystemExit(\"Nenhuma imagem encontrada em images_dir\")\n",
        "\n",
        "    # --- PASSO A: Replicar o split 80/20 original ---\n",
        "    print(\"Coletando metadados das imagens-fonte...\")\n",
        "    image_meta = []\n",
        "    for img_name in all_images:\n",
        "        stem = Path(img_name).stem\n",
        "        lbl = ensure_label_file(labels_dir, stem)\n",
        "        img_path = os.path.join(images_dir, img_name)\n",
        "        try:\n",
        "            with Image.open(img_path) as im:\n",
        "                w, h = im.size\n",
        "        except:\n",
        "            print(f\"Aviso: Falha ao abrir {img_path}, pulando.\")\n",
        "            continue\n",
        "        boxes = read_yolo_labels(lbl)\n",
        "        dom = dominant_class_for_image(boxes)\n",
        "        image_meta.append({\"img\": img_name, \"stem\": stem, \"w\": w, \"h\": h, \"boxes\": boxes, \"dom\": dom})\n",
        "\n",
        "    print(\"Replicando o split de treino estratificado 80/20...\")\n",
        "    groups = defaultdict(list)\n",
        "    for m in image_meta:\n",
        "        groups[m[\"dom\"]].append(m)\n",
        "\n",
        "    train_images = []\n",
        "    test_images = [] # Não vamos usar, mas mantemos para a lógica ser idêntica\n",
        "    for dom, items in groups.items():\n",
        "        random.shuffle(items) # <-- Graças ao seed 42, isto é idêntico\n",
        "        split = int(0.8 * len(items))\n",
        "        train_images.extend(items[:split])\n",
        "        test_images.extend(items[split:])\n",
        "\n",
        "    print(f\"Split replicado. {len(train_images)} imagens-fonte de treino encontradas.\")\n",
        "\n",
        "    # --- PASSO B: Fazer o Tiling e Salvar (Localmente) ---\n",
        "\n",
        "    # Limpa a pasta local, se já existir\n",
        "    if os.path.exists(LOCAL_OUTPUT_ROOT):\n",
        "        print(f\"Limpando pasta local antiga: {LOCAL_OUTPUT_ROOT}\")\n",
        "        shutil.rmtree(LOCAL_OUTPUT_ROOT)\n",
        "\n",
        "    global_tile_counter = {\"value\": 1}\n",
        "    total_tiles_created = 0\n",
        "    print(f\"Começando o tiling (local) para salvar APENAS backgrounds...\")\n",
        "\n",
        "    for img_meta in train_images: # <-- Itera APENAS nas imagens de treino\n",
        "        count = save_negative_tiles_only(\n",
        "            img_meta,\n",
        "            LOCAL_OUTPUT_ROOT,\n",
        "            tile_size=tile_size,\n",
        "            overlap=overlap,\n",
        "            counter_dict=global_tile_counter\n",
        "        )\n",
        "        if count > 0:\n",
        "            print(f\"Processando {img_meta['img']}... -> Salvos {count} tiles de background.\")\n",
        "        total_tiles_created += count\n",
        "\n",
        "    print(\"\\n--- Tiling Local Concluído ---\")\n",
        "    print(f\"Total de tiles de background recuperados: {total_tiles_created}\")\n",
        "\n",
        "    # --- PASSO C: Verificar e Copiar para o Drive ---\n",
        "    local_img_folder = os.path.join(LOCAL_OUTPUT_ROOT, \"images\")\n",
        "    if os.path.exists(local_img_folder):\n",
        "        real_count = len(os.listdir(local_img_folder))\n",
        "        print(f\"Verificação local: {real_count} tiles existem na pasta local.\")\n",
        "\n",
        "        if real_count == total_tiles_created and real_count > 0:\n",
        "            print(f\"\\nCopiando {real_count} tiles para o Google Drive...\")\n",
        "\n",
        "            drive_img_folder = os.path.join(DRIVE_OUTPUT_ROOT, \"images\")\n",
        "\n",
        "            if os.path.exists(drive_img_folder):\n",
        "                print(f\"Limpando pasta de destino antiga no Drive: {drive_img_folder}\")\n",
        "                shutil.rmtree(drive_img_folder)\n",
        "\n",
        "            print(f\"De: {local_img_folder}\")\n",
        "            print(f\"Para: {drive_img_folder}\")\n",
        "\n",
        "            shutil.copytree(local_img_folder, drive_img_folder)\n",
        "            print(\"Cópia para o Google Drive concluída!\")\n",
        "\n",
        "            print(\"\\n[PRÓXIMO PASSO]\")\n",
        "            print(f\"Adicione os {real_count} ficheiros de:\")\n",
        "            print(f\"'{drive_img_folder}'\")\n",
        "            print(\"Para a sua pasta de treino original:\")\n",
        "            print(\"'/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/images'\")\n",
        "        else:\n",
        "            print(f\"[ERRO] A contagem local ({real_count}) não bate com a esperada ({total_tiles_created}).\")\n",
        "    else:\n",
        "         print(\"[ERRO] A pasta local de tiles não foi criada.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AbmbaLp9ZgG",
        "outputId": "88bdcc92-b64d-4837-cb95-dc5926b00980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando transferência de ficheiros de background...\n",
            "Pasta de origem (/content/drive/MyDrive/tcc_dengue/ia_deteccao/Discarded_Backgrounds/images) contém: 1273 ficheiros.\n",
            "Pasta de destino (/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/images) contém: 1810 ficheiros.\n",
            "\n",
            "Iniciando a cópia...\n",
            "Progresso: 1273 / 1273 copiados.\n",
            "Cópia concluída.\n",
            "Verificando a contagem final...\n",
            "Contagem inicial: 1810\n",
            "Ficheiros adicionados: 1273\n",
            "Contagem final na pasta: 3083\n",
            "Contagem total esperada: 3083\n",
            "\n",
            "✅ SUCESSO! A contagem de ficheiros está correta.\n",
            "O seu dataset de treino está pronto para o fine-tuning final.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "SOURCE_DIR = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Discarded_Backgrounds/images\"\n",
        "DESTINATION_DIR = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/images\"\n",
        "print(\"Iniciando transferência de ficheiros de background...\")\n",
        "\n",
        "if not os.path.exists(SOURCE_DIR):\n",
        "    print(f\"[ERRO FATAL] A pasta de origem não existe: {SOURCE_DIR}\")\n",
        "    sys.exit(1)\n",
        "if not os.path.exists(DESTINATION_DIR):\n",
        "    print(f\"[ERRO FATAL] A pasta de destino não existe: {DESTINATION_DIR}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "files_to_copy = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.jpg')]\n",
        "num_to_copy = len(files_to_copy)\n",
        "\n",
        "if num_to_copy == 0:\n",
        "    print(f\"[ERRO] Nenhum ficheiro .jpg encontrado em {SOURCE_DIR}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    initial_count = len([f for f in os.listdir(DESTINATION_DIR) if f.endswith('.jpg')])\n",
        "except Exception as e:\n",
        "    print(f\"[ERRO] Não foi possível ler a pasta de destino: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"Pasta de origem ({SOURCE_DIR}) contém: {num_to_copy} ficheiros.\")\n",
        "print(f\"Pasta de destino ({DESTINATION_DIR}) contém: {initial_count} ficheiros.\")\n",
        "print(\"\\nIniciando a cópia...\")\n",
        "\n",
        "for i, filename in enumerate(files_to_copy):\n",
        "    source_path = os.path.join(SOURCE_DIR, filename)\n",
        "    destination_path = os.path.join(DESTINATION_DIR, filename)\n",
        "\n",
        "    if not os.path.exists(destination_path):\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "\n",
        "    if (i + 1) % 25 == 0 or (i + 1) == num_to_copy:\n",
        "        print(f\"Progresso: {i + 1} / {num_to_copy} copiados.\", end='\\r')\n",
        "\n",
        "print(\"\\nCópia concluída.\")\n",
        "\n",
        "# --- 4. VERIFICAÇÃO FINAL ---\n",
        "print(\"Verificando a contagem final...\")\n",
        "try:\n",
        "    final_count = len([f for f in os.listdir(DESTINATION_DIR) if f.endswith('.jpg')])\n",
        "except Exception as e:\n",
        "    print(f\"[ERRO] Não foi possível ler a pasta de destino após a cópia: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "expected_total_count = initial_count + num_to_copy\n",
        "\n",
        "print(f\"Contagem inicial: {initial_count}\")\n",
        "print(f\"Ficheiros adicionados: {num_to_copy}\")\n",
        "print(f\"Contagem final na pasta: {final_count}\")\n",
        "print(f\"Contagem total esperada: {expected_total_count}\")\n",
        "\n",
        "if final_count == expected_total_count:\n",
        "    print(\"\\n✅ SUCESSO! A contagem de ficheiros está correta.\")\n",
        "    print(\"O seu dataset de treino está pronto para o fine-tuning final.\")\n",
        "else:\n",
        "    print(f\"\\n[AVISO!] A contagem final ({final_count}) não bate com a esperada ({expected_total_count}).\")\n",
        "    print(\"Pode haver ficheiros duplicados ou um erro de cópia. Verifique as pastas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_fl09Va_9W9"
      },
      "source": [
        "# Treinando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "mE2fzUYGBU5H",
        "outputId": "b1885c68-17eb-430b-eeac-1670b722ef0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.217 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml, degrees=10.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.0, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.03, hsv_s=0.5, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00015, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/dengue_detection_testeI11/weights/best.pt, momentum=0.937, mosaic=0.2, multi_scale=False, name=tiled_yolov8m_tilesFINAL, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolov8m_tilesFINAL, save_frames=False, save_json=False, save_period=30, save_txt=False, scale=0.1, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.002, workers=6, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 22.5MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3779749  ultralytics.nn.modules.head.Detect           [7, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,860,373 parameters, 25,860,357 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 475/475 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 99.6MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 8.7±17.8 ms, read: 1.3±0.3 MB/s, size: 378.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/labels.cache... 1682 images, 1401 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3083/3083 4.4Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.8±2.2 ms, read: 1.5±0.2 MB/s, size: 413.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/test/labels.cache... 810 images, 403 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 403.9Kit/s 0.0s\n",
            "Plotting labels to /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolov8m_tilesFINAL/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00015, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.002), 83 bias(decay=0.0)\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolov8m_tilesFINAL\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      3.59G      1.067      1.347      1.195          5       1024: 23% ━━╸───────── 90/386 1.3it/s 4:07<3:46\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3227676559.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpretrained_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8m.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTQDM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;31m# Warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_yaml_path = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml\"\n",
        "project_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs\"\n",
        "old_run_name = \"dengue_detection_testeI11\"\n",
        "pretrained_best = Path(f\"{project_dir}/{old_run_name}/weights/best.pt\")\n",
        "\n",
        "run_name = \"tiled_yolov8m_tilesFINAL\"\n",
        "\n",
        "train_args = {\n",
        "    \"data\": dataset_yaml_path,\n",
        "    \"epochs\": 100,\n",
        "    \"imgsz\": 1024,\n",
        "    \"project\": project_dir,\n",
        "    \"name\": run_name,\n",
        "    \"save\": True,\n",
        "    \"save_period\": 30,\n",
        "    \"batch\": 8,\n",
        "    \"workers\": 6,\n",
        "    \"patience\": 30,\n",
        "    \"exist_ok\": True,\n",
        "    \"rect\": False,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"lr0\": 0.00015,\n",
        "    \"freeze\": 10,\n",
        "    \"lrf\": 0.01,\n",
        "    \"weight_decay\": 0.002,\n",
        "    \"seed\": 42,\n",
        "    \"hsv_h\": 0.03,\n",
        "    \"hsv_s\": 0.5,\n",
        "    \"hsv_v\": 0.4,\n",
        "    \"degrees\": 10.0,\n",
        "    \"translate\": 0.1,\n",
        "    \"scale\": 0.1,\n",
        "    \"fliplr\": 0.5,\n",
        "    \"flipud\": 0.0,\n",
        "    \"mosaic\": 0.2,\n",
        "    \"mixup\": 0.1,\n",
        "    \"copy_paste\": 0.1,\n",
        "    \"erasing\": 0.0,\n",
        "}\n",
        "\n",
        "if pretrained_best.exists():\n",
        "    model = YOLO(str(pretrained_best))\n",
        "    model.train(**train_args)\n",
        "else:\n",
        "    model = YOLO(\"yolov8m.pt\")\n",
        "    model.train(**train_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGTL_qRO62Ac",
        "outputId": "61e8f1c4-d3b2-43e7-ce37-ec16594fc0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint 'last.pt' encontrado em: /content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds/weights/last.pt\n",
            "Continuando (resumindo) o treino da run 'tiled_yolo8m_fineTunedBackGrounds'...\n",
            "Ultralytics 8.3.217 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml, degrees=10.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=0, half=False, hsv_h=0.03, hsv_s=0.5, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds/weights/last.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=tiled_yolo8m_fineTunedBackGrounds, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs, rect=False, resume=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=6, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3779749  ultralytics.nn.modules.head.Detect           [7, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,860,373 parameters, 25,860,357 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 475/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.6±0.1 ms, read: 103.0±29.8 MB/s, size: 379.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/train/labels.cache... 1682 images, 1401 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3083/3083 4.2Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.0±0.6 ms, read: 39.1±14.8 MB/s, size: 425.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/test/labels.cache... 810 images, 403 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 141.3Kit/s 0.0s\n",
            "Plotting labels to /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=1e-05, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Resuming training /content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds/weights/last.pt from epoch 45 to 50 total epochs\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/tiled_yolo8m_fineTunedBackGrounds\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      13.5G     0.5852     0.3303     0.8947         18       1024: 68% ━━━━━━━━──── 263/386 1.6it/s 2:53<1:19"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "dataset_yaml_path = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml\"\n",
        "project_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs\"\n",
        "\n",
        "# Modelo BASE para transfer learning (usado apenas se for um NOVO treino)\n",
        "source_run_name = \"tiled_yolo8m_fineTuned\"\n",
        "model_to_fine_tune = Path(f\"{project_dir}/{source_run_name}/weights/best.pt\")\n",
        "\n",
        "target_run_name = \"tiled_yolo8m_fineTunedBackGrounds\"\n",
        "resume_checkpoint = Path(f\"{project_dir}/{target_run_name}/weights/last.pt\")\n",
        "\n",
        "fine_tune_args = {\n",
        "    \"data\": dataset_yaml_path,\n",
        "    \"lr0\": 1e-5,\n",
        "    \"epochs\": 50,\n",
        "    \"patience\": 20,\n",
        "    \"freeze\": 0,\n",
        "    \"mosaic\": 0.0,\n",
        "    \"mixup\": 0.0,\n",
        "    \"copy_paste\": 0.0,\n",
        "    \"imgsz\": 1024,\n",
        "    \"project\": project_dir,\n",
        "    \"name\": target_run_name,\n",
        "    \"batch\": 8,\n",
        "    \"workers\": 6,\n",
        "    \"exist_ok\": True,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"hsv_h\": 0.03,\n",
        "    \"hsv_s\": 0.5,\n",
        "    \"hsv_v\": 0.4,\n",
        "    \"degrees\": 10.0,\n",
        "    \"translate\": 0.1,\n",
        "    \"scale\": 0.1,\n",
        "    \"fliplr\": 0.5,\n",
        "}\n",
        "\n",
        "# Lógica de Resumo: Verifica se o 'last.pt' da run ALVO existe\n",
        "if resume_checkpoint.exists():\n",
        "    print(f\"Checkpoint 'last.pt' encontrado em: {resume_checkpoint}\")\n",
        "    print(f\"Continuando (resumindo) o treino da run '{target_run_name}'...\")\n",
        "    model = YOLO(str(resume_checkpoint))\n",
        "    model.train(resume=True)\n",
        "\n",
        "    print(\"Treino (resumido) concluído.\")\n",
        "\n",
        "# Lógica de Novo Treino: Se 'last.pt' não existe, começa um novo fine-tuning\n",
        "else:\n",
        "    print(f\"Nenhum checkpoint 'last.pt' encontrado em '{target_run_name}'.\")\n",
        "    print(f\"Verificando modelo base para novo fine-tuning...\")\n",
        "    if not model_to_fine_tune.exists():\n",
        "        print(f\"[ERRO FATAL] O modelo base 'best.pt' para fine-tuning não foi encontrado em:\")\n",
        "        print(f\"{model_to_fine_tune}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Iniciando NOVO fine-tuning (HNM)...\")\n",
        "        print(f\"Carregando modelo base de: {model_to_fine_tune}\")\n",
        "        print(f\"Salvando nova run em: {project_dir}/{target_run_name}\")\n",
        "        model = YOLO(str(model_to_fine_tune))\n",
        "        model.train(**fine_tune_args)\n",
        "\n",
        "        print(\"Fine-tuning (novo) concluído.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV-FwVnRPXUm"
      },
      "source": [
        "# Testando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAyrywLvuaFe",
        "outputId": "d4a0d3aa-23bd-4250-e35f-66a8d4c8d712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.217 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 92 layers, 25,843,813 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 167.5MB/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.2 ms, read: 0.5±0.1 MB/s, size: 432.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/tiles/test/labels.cache... 810 images, 403 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 1.2Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 51/51 0.8it/s 1:05\n",
            "                   all        810       1643      0.768      0.707      0.762      0.535\n",
            "         piscina_limpa         14         14      0.667      0.857      0.838      0.666\n",
            "          piscina_suja         20         20      0.667       0.75      0.802      0.674\n",
            "                  lona        139        208      0.864      0.812      0.825      0.627\n",
            "         monte_de_lixo        261        490      0.761      0.661      0.719      0.507\n",
            "  reservatorio_de_agua         67        117      0.802      0.624      0.644      0.397\n",
            "                  pneu         43        227      0.876       0.75      0.877      0.505\n",
            "          saco_de_lixo         83        567      0.742      0.496      0.629       0.37\n",
            "Speed: 3.7ms preprocess, 49.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "=== Métricas gerais ===\n",
            "Mean Precision: 0.768\n",
            "Mean Recall: 0.707\n",
            "mAP@0.5: 0.762\n",
            "mAP@0.5:0.95: 0.535\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "run_name = \"dengue_detection_testeI11\"\n",
        "run_name = \"tiled_yolov8m_tilesFINAL\"\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2\"\n",
        "model_dir = os.path.join(base_dir, \"modelo_final\", \"runs\", run_name, \"weights\", \"best.pt\")\n",
        "dataset_yaml_path = os.path.join(base_dir, \"dataset.yml\")\n",
        "\n",
        "model = YOLO(model_dir)\n",
        "metrics = model.val(data=dataset_yaml_path)\n",
        "\n",
        "mean_precision, mean_recall, map50, map50_95 = metrics.mean_results()\n",
        "print(\"=== Métricas gerais ===\")\n",
        "print(f\"Mean Precision: {mean_precision:.3f}\")\n",
        "print(f\"Mean Recall: {mean_recall:.3f}\")\n",
        "print(f\"mAP@0.5: {map50:.3f}\")\n",
        "print(f\"mAP@0.5:0.95: {map50_95:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBAgx-cIAABW"
      },
      "source": [
        "# Rascunho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfpTevuFZ06_"
      },
      "outputs": [],
      "source": [
        "'''from pathlib import Path\n",
        "\n",
        "dataset_yaml_path = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/modelo_final/dataset.yaml\"\n",
        "project_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/modelo_final/runs\"\n",
        "run_name = \"dengue_detectionSmall\"\n",
        "\n",
        "# Verifica se existe um modelo anterior salvo\n",
        "resume_path = Path(f\"{project_dir}/{run_name}/weights/last.pt\")\n",
        "\n",
        "if resume_path.exists():\n",
        "    print(\"✅ Retomando treino do último checkpoint...\")\n",
        "    model = YOLO(f\"{resume_path}\")\n",
        "    model.train(\n",
        "        resume=True,\n",
        "        exist_ok=True,\n",
        "        data=dataset_yaml_path,\n",
        "        epochs=80, # Para o pro: 150\n",
        "        imgsz=960, #antes: 600\n",
        "        project=project_dir,\n",
        "        name=run_name,\n",
        "        save=True,\n",
        "        save_period=5, # Salvar a cada 5 épocas\n",
        "        batch=16,  # Para o Pro: 32\n",
        "        workers=2, # Para o Pro: 4\n",
        "        patience=20,  # se overfitting, para cedo, para o Pro: 35\n",
        "    )\n",
        "else:\n",
        "    print(\"🆕 Iniciando novo treino do zero...\")\n",
        "    model = YOLO(\"yolov8s.pt\") # Para o Pro: \"yolov8m.pt\"\n",
        "    model.train(\n",
        "        data=dataset_yaml_path,\n",
        "        epochs=80, # Para o pro: 150\n",
        "        imgsz=640,\n",
        "        project=project_dir,\n",
        "        name=run_name,\n",
        "        save=True,\n",
        "        save_period=5, # Salvar a cada 5 épocas\n",
        "        batch=16,  # Para o Pro: 32\n",
        "        workers=2, # Para o Pro: 4\n",
        "        patience=20,  # se overfitting, para cedo, para o Pro: 35\n",
        "    )\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW6H7g7uTCyb",
        "outputId": "e542f5d1-5d4f-419a-82c5-4274ccc15461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_seed: 42\n",
            "total images: 251\n",
            "train images: 200\n",
            "test images: 51\n",
            "train boxes: 4035\n",
            "test boxes: 841\n",
            "train class distribution: {0: 59, 1: 59, 2: 424, 3: 1037, 4: 215, 5: 1070, 6: 1171}\n",
            "test class distribution: {0: 15, 1: 14, 2: 115, 3: 229, 4: 60, 5: 175, 6: 233}\n",
            "dataset.yml: /content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml\n",
            "nc: 7\n",
            "names: ['piscina_limpa', 'piscina_suja', 'lona', 'monte_de_lixo', 'reservatorio_de_agua', 'pneu', 'saco_de_lixo']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import yaml\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Sao_Carlos_imagens\"\n",
        "labels_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Sao_Carlos_finalAnnotations\"\n",
        "output_root = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2\"\n",
        "train_img_dir = os.path.join(output_root, \"train\", \"images\")\n",
        "train_lbl_dir = os.path.join(output_root, \"train\", \"labels\")\n",
        "test_img_dir = os.path.join(output_root, \"test\", \"images\")\n",
        "test_lbl_dir = os.path.join(output_root, \"test\", \"labels\")\n",
        "os.makedirs(train_img_dir, exist_ok=True)\n",
        "os.makedirs(train_lbl_dir, exist_ok=True)\n",
        "os.makedirs(test_img_dir, exist_ok=True)\n",
        "os.makedirs(test_lbl_dir, exist_ok=True)\n",
        "\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "\n",
        "# --- Funções Utilitárias (sem alterações) ---\n",
        "def numeric_key(filename):\n",
        "    name = Path(filename).stem\n",
        "    m = re.match(r\"^(\\d+)$\", name)\n",
        "    if m:\n",
        "        return int(m.group(1))\n",
        "    nums = re.findall(r\"\\d+\", name)\n",
        "    return int(nums[0]) if nums else name\n",
        "\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "all_images = [f for f in os.listdir(images_dir) if Path(f).suffix.lower() in image_extensions]\n",
        "if not all_images:\n",
        "    raise SystemExit(\"no images found in images_dir\")\n",
        "all_images_sorted = sorted(all_images, key=numeric_key)\n",
        "random.shuffle(all_images_sorted)\n",
        "total = len(all_images_sorted)\n",
        "split_idx = int(0.8 * total)\n",
        "train_images = all_images_sorted[:split_idx]\n",
        "test_images = all_images_sorted[split_idx:]\n",
        "\n",
        "def ensure_label_exists(labels_dir, base_stem):\n",
        "    src = os.path.join(labels_dir, base_stem + \".txt\")\n",
        "    if not os.path.exists(src):\n",
        "        open(src, \"a\").close()\n",
        "    return src\n",
        "\n",
        "\n",
        "CLASSES_TO_REMOVE = {5, 8}\n",
        "\n",
        "CLASS_REMAPPING = {\n",
        "    6: 5,\n",
        "    7: 6\n",
        "}\n",
        "\n",
        "def process_and_copy_label(src_path, dst_path):\n",
        "    \"\"\"Lê um arquivo de anotação, remove/re-indexa classes e salva no destino.\"\"\"\n",
        "    new_lines = []\n",
        "    with open(src_path, \"r\") as f_in:\n",
        "        for line in f_in:\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                original_cls = int(float(parts[0]))\n",
        "\n",
        "                if original_cls in CLASSES_TO_REMOVE:\n",
        "                    continue\n",
        "\n",
        "                new_cls = CLASS_REMAPPING.get(original_cls, original_cls)\n",
        "\n",
        "                new_line = f\"{new_cls} {' '.join(parts[1:])}\"\n",
        "                new_lines.append(new_line)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    with open(dst_path, \"w\") as f_out:\n",
        "        f_out.write(\"\\n\".join(new_lines))\n",
        "\n",
        "\n",
        "# --- Processamento e Cópia dos Arquivos ---\n",
        "for img_list, dest_img_dir, dest_lbl_dir in [\n",
        "    (train_images, train_img_dir, train_lbl_dir),\n",
        "    (test_images, test_img_dir, test_lbl_dir),\n",
        "]:\n",
        "    for img_name in img_list:\n",
        "        src_img = os.path.join(images_dir, img_name)\n",
        "        dst_img = os.path.join(dest_img_dir, img_name)\n",
        "        shutil.copy2(src_img, dst_img)\n",
        "\n",
        "        base = Path(img_name).stem\n",
        "        lbl_src = ensure_label_exists(labels_dir, base)\n",
        "        dst_lbl = os.path.join(dest_lbl_dir, base + \".txt\")\n",
        "        process_and_copy_label(lbl_src, dst_lbl)\n",
        "\n",
        "train_counter = Counter()\n",
        "test_counter = Counter()\n",
        "def count_classes_in_dir(labels_dir, counter):\n",
        "    total_boxes = 0\n",
        "    for fname in os.listdir(labels_dir):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "        path = os.path.join(labels_dir, fname)\n",
        "        with open(path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if not parts:\n",
        "                    continue\n",
        "                try:\n",
        "                    cid = int(float(parts[0]))\n",
        "                    counter[cid] += 1\n",
        "                    total_boxes += 1\n",
        "                except:\n",
        "                    continue\n",
        "    return total_boxes\n",
        "\n",
        "train_total_boxes = count_classes_in_dir(train_lbl_dir, train_counter)\n",
        "test_total_boxes = count_classes_in_dir(test_lbl_dir, test_counter)\n",
        "\n",
        "names = [\n",
        "    'piscina_limpa',        # 0\n",
        "    'piscina_suja',         # 1\n",
        "    'lona',                 # 2\n",
        "    'monte_de_lixo',        # 3\n",
        "    'reservatorio_de_agua', # 4\n",
        "    'pneu',                 # 5 (era 6)\n",
        "    'saco_de_lixo'          # 6 (era 7)\n",
        "]\n",
        "nc = len(names)\n",
        "\n",
        "dataset_yml = {\n",
        "    \"train\": train_img_dir,\n",
        "    \"val\": test_img_dir,\n",
        "    \"test\": test_img_dir,\n",
        "    \"nc\": nc,\n",
        "    \"names\": names\n",
        "}\n",
        "\n",
        "dataset_yml_path = os.path.join(output_root, \"dataset.yml\")\n",
        "with open(dataset_yml_path, \"w\") as yf:\n",
        "    yaml.dump(dataset_yml, yf, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(\"random_seed:\", random_seed)\n",
        "print(\"total images:\", total)\n",
        "print(\"train images:\", len(train_images))\n",
        "print(\"test images:\", len(test_images))\n",
        "print(\"train boxes:\", train_total_boxes)\n",
        "print(\"test boxes:\", test_total_boxes)\n",
        "print(\"train class distribution:\", dict(sorted(train_counter.items())))\n",
        "print(\"test class distribution:\", dict(sorted(test_counter.items())))\n",
        "print(\"dataset.yml:\", dataset_yml_path)\n",
        "print(\"nc:\", nc)\n",
        "print(\"names:\", names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqvoalFni5QW",
        "outputId": "1187fcc6-9752-49e7-a7e8-e592289e7b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🆕 Iniciando novo treino do zero com YOLOv8m...\n",
            "Ultralytics 8.3.215 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=ram, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml, degrees=10.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=120, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1408, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=dengue_detection_50porcento3, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/dengue_detection_50porcento3, save_frames=False, save_json=False, save_period=15, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=6, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3779749  ultralytics.nn.modules.head.Detect           [7, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,860,373 parameters, 25,860,357 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.6±0.2 ms, read: 336.0±243.9 MB/s, size: 8052.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/train/labels.cache... 200 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 122.6Kit/s 0.0s\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB RAM): 100% ━━━━━━━━━━━━ 200/200 6.1it/s 33.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.9±0.5 ms, read: 167.2±70.7 MB/s, size: 7854.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/test/labels.cache... 51 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 51/51 9.2Kit/s 0.0s\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB RAM): 100% ━━━━━━━━━━━━ 51/51 6.3it/s 8.1s\n",
            "Plotting labels to /content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/dengue_detection_50porcento3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 1408 train, 1408 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/.shortcut-targets-by-id/1iqKFMZvfF0pgK9N8REMQ7NqepaG-Pnv3/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs/dengue_detection_50porcento3\u001b[0m\n",
            "Starting training for 120 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/120      8.84G      2.022      5.255      1.443         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.8it/s 2.5s\n",
            "                   all         51        841      0.349      0.106     0.0477     0.0247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/120      8.57G      1.668      3.214      1.227         90       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.4it/s 2.0s\n",
            "                   all         51        841      0.422      0.185      0.102     0.0583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/120      8.04G       1.62       3.11      1.164         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.7it/s 1.9s\n",
            "                   all         51        841      0.538      0.203      0.129     0.0757\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/120      8.23G      1.555      3.482      1.143         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.5it/s 2.0s\n",
            "                   all         51        841      0.352      0.237      0.141     0.0851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/120      8.22G      1.589      2.808      1.104         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.319      0.273      0.173      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/120      7.78G      1.599      2.954      1.116         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.6it/s 1.9s\n",
            "                   all         51        841      0.731      0.182      0.224      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/120      8.21G      1.576      2.546      1.119         90       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.6it/s 2.0s\n",
            "                   all         51        841      0.617      0.223      0.185      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/120      8.21G      1.616      2.308      1.186         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.7it/s 1.9s\n",
            "                   all         51        841      0.399      0.294      0.222      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/120      8.23G      1.575      2.032      1.151         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.441      0.309      0.237      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/120      8.02G      1.501      1.956      1.108         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.227      0.363      0.244      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/120      8.17G      1.587      1.876      1.171         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.5it/s 2.0s\n",
            "                   all         51        841      0.269      0.385       0.26      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/120      8.24G      1.531      1.673      1.129         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.397      0.357      0.266      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/120      8.23G      1.507      1.629      1.116         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.406      0.398      0.284      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/120      8.05G      1.419      1.591       1.08         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.4it/s 2.0s\n",
            "                   all         51        841      0.438      0.348      0.279      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/120      8.19G      1.428      1.566      1.059         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.287      0.348      0.292      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/120      8.24G      1.454       1.45      1.061         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.518        0.3       0.29       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/120      7.79G      1.416      1.413      1.055         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841       0.65      0.273      0.303      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/120      8.13G      1.415      1.274      1.036         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.7it/s 1.9s\n",
            "                   all         51        841      0.485      0.301      0.296      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/120      8.22G       1.37      1.281      1.016         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841       0.44      0.319      0.296       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/120      8.24G      1.453      1.203      1.042         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.9s\n",
            "                   all         51        841      0.326      0.377      0.294      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/120       8.2G      1.362      1.182      1.012         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.7it/s 1.9s\n",
            "                   all         51        841      0.533      0.322      0.282      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/120      8.19G      1.357      1.119      1.027         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.333      0.338      0.271      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/120      8.21G      1.371      1.053      1.022         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.391      0.315      0.273      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/120      8.18G      1.391      1.028      1.031         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.393      0.297      0.267      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/120      8.09G      1.349     0.9661      1.009         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.434        0.3      0.277       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/120      8.02G      1.287     0.9131      1.003         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.339      0.347      0.292      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/120      8.09G      1.305      0.905      1.007         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.375      0.392       0.32      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/120      8.23G      1.265     0.8997     0.9874         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.281      0.395      0.297      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/120       8.2G      1.261     0.8609     0.9849         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s\n",
            "                   all         51        841      0.384      0.347        0.3      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/120      8.06G      1.255     0.8427     0.9824         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.448      0.327        0.3      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/120      8.26G      1.231     0.8055     0.9735         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.667      0.248      0.276      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/120       8.2G       1.25     0.8103     0.9838         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.441      0.304      0.293      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/120      8.26G      1.251     0.7795      0.973         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.304      0.359      0.279       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/120      8.07G      1.221     0.7405     0.9608         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.342      0.366      0.298      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/120      8.61G      1.224     0.7404     0.9613         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.422      0.363       0.31      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/120      8.23G      1.187     0.7065     0.9482         90       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s\n",
            "                   all         51        841      0.392      0.356      0.316      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/120       8.2G      1.192     0.6969     0.9561         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.357      0.358      0.301      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/120      8.21G      1.183     0.6884       0.95         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.337      0.345      0.299      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/120      8.12G      1.191     0.6886     0.9492         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.367      0.315      0.279      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/120       8.1G      1.194     0.7185     0.9588         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.437      0.302      0.271      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/120      8.19G      1.154     0.6689      0.938         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.429      0.354      0.334      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/120      7.92G      1.147     0.6369     0.9375         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.424      0.344      0.311       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/120      8.18G      1.173     0.6401     0.9433         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.378      0.345      0.305      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/120      8.22G      1.117     0.6402     0.9361         86       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.319      0.354      0.276       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/120      8.23G      1.114     0.6204     0.9261         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s\n",
            "                   all         51        841      0.394      0.356      0.285      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/120      8.11G      1.117     0.6267     0.9268         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.324      0.355      0.268      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/120      8.26G       1.09     0.6072     0.9209         85       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841       0.31      0.393      0.288       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/120      8.24G      1.128     0.6398     0.9265         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s\n",
            "                   all         51        841      0.446      0.332      0.305      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/120      8.21G      1.099     0.6121     0.9277         84       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.353      0.374      0.303      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/120      8.52G       1.09     0.5996     0.9203         90       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.335       0.38      0.308      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/120      8.22G      1.088     0.6088     0.9179         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.307      0.375      0.296      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/120      8.23G      1.087     0.6101     0.9187         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.433      0.289      0.284      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/120       8.2G      1.073     0.6093     0.9158         90       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841       0.32      0.342      0.297      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/120      8.22G      1.052     0.5594     0.9093         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.397      0.345      0.329       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/120      8.23G      1.033     0.5907      0.902         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 20.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s\n",
            "                   all         51        841      0.405      0.403      0.341       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/120       8.1G      1.063     0.5696     0.9074         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.6it/s 1.9s\n",
            "                   all         51        841      0.414      0.343      0.326      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/120      8.21G      1.043     0.5773     0.9056         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.363      0.328      0.322       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/120      8.04G      1.059     0.5702      0.909         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.413      0.349      0.324      0.206\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/120      8.21G       1.05     0.5573     0.9106         87       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s\n",
            "                   all         51        841      0.329      0.374      0.326      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/120      8.23G       1.03     0.5574     0.8989         90       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.9s\n",
            "                   all         51        841      0.406      0.316      0.321      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/120      8.19G      1.017     0.5338     0.8978         88       1408: 100% ━━━━━━━━━━━━ 50/50 2.6it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s\n",
            "                   all         51        841      0.386      0.341      0.316        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/120      8.23G      1.033     0.5412     0.8982         89       1408: 100% ━━━━━━━━━━━━ 50/50 2.5it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s\n",
            "                   all         51        841      0.466      0.335      0.325      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "# --- CONFIGURAÇÃO DE CAMINHOS ---\n",
        "dataset_yaml_path = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/dataset.yml\"\n",
        "project_dir = \"/content/drive/MyDrive/tcc_dengue/ia_deteccao/Teste_Treino_2/modelo_final/runs\"\n",
        "run_name = \"dengue_detection_50porcento3\"\n",
        "\n",
        "# Verifica se existe um modelo anterior salvo\n",
        "resume_path = Path(f\"{project_dir}/{run_name}/weights/last.pt\")\n",
        "\n",
        "# --- ARGUMENTOS DE TREINAMENTO ---\n",
        "train_args = {\n",
        "    \"data\": dataset_yaml_path,\n",
        "    \"epochs\": 120,\n",
        "    \"imgsz\": 1408,\n",
        "    \"project\": project_dir,\n",
        "    \"name\": run_name,\n",
        "    \"save\": True,\n",
        "    \"save_period\": 15,\n",
        "    \"batch\": 4,\n",
        "    \"workers\": 6,\n",
        "    \"patience\": 30,\n",
        "    \"exist_ok\": True,\n",
        "    \"rect\": True,\n",
        "    \"optimizer\": \"SGD\",\n",
        "    \"lr0\": 0.01,\n",
        "    \"lrf\": 0.01,\n",
        "    \"weight_decay\": 0.0005,\n",
        "\n",
        "    \"degrees\": 10.0,\n",
        "    \"translate\": 0.1,\n",
        "    \"scale\": 0.1,\n",
        "    \"fliplr\": 0.5,\n",
        "    \"mosaic\": 1.0,\n",
        "    \"mixup\": 0.1,\n",
        "    \"copy_paste\": 0.1,\n",
        "    \"cache\": \"ram\"\n",
        "}\n",
        "\n",
        "if resume_path.exists():\n",
        "    print(\"✅ Retomando treino do último checkpoint...\")\n",
        "    model = YOLO(f\"{resume_path}\")\n",
        "    model.train(resume=True, **train_args)\n",
        "else:\n",
        "    print(\"🆕 Iniciando novo treino do zero com YOLOv8m...\")\n",
        "    model = YOLO(\"yolov8m.pt\")\n",
        "    model.train(**train_args)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jV-FwVnRPXUm",
        "PBAgx-cIAABW"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
